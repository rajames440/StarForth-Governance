// Jenkinsfile.disposition
// Document Disposition Pipeline - Main Orchestrator
// Manages the complete lifecycle of documents from in_basket to signed vault

pipeline {
    agent any

    parameters {
        booleanParam(
            name: 'DRY_RUN',
            defaultValue: false,
            description: 'Dry run mode (no commits/pushes)'
        )
        string(
            name: 'PROCESS_DOCUMENT',
            defaultValue: '',
            description: 'Process specific document (filename). Leave empty for all.'
        )
    }

    triggers {
        // Poll for changes to in_basket every 15 minutes
        pollSCM('H/15 * * * *')
    }

    options {
        buildDiscarder(logRotator(numToKeepStr: '50'))
        timeout(time: 2, unit: 'HOURS')
        disableConcurrentBuilds()
        timestamps()
    }

    environment {
        GOVERNANCE_REPO = 'rajames440/StarForth-Governance'
        WORKSPACE_REPO = "${WORKSPACE}"
        IN_BASKET = "${WORKSPACE_REPO}/in_basket"
        PENDING = "${WORKSPACE_REPO}/Pending"
        SEC_LOG = "${WORKSPACE_REPO}/Security/SEC_LOG.adoc"
        SIGNATURES_FILE = "${WORKSPACE_REPO}/Security/Signatures.adoc"
        GIT_AUTHOR_NAME = "Disposition Pipeline"
        GIT_AUTHOR_EMAIL = "disposition@starforth.governance"
        TIMESTAMP = sh(script: 'date -u +%Y-%m-%dT%H:%M:%SZ', returnStdout: true).trim()
    }

    stages {
        stage('Checkout') {
            steps {
                script {
                    echo "üìã Checking out StarForth-Governance repository..."
                    checkout([
                        $class: 'GitSCM',
                        branches: [[name: '*/master']],
                        userRemoteConfigs: [[
                            url: "https://github.com/${GOVERNANCE_REPO}.git",
                            credentialsId: 'github-credentials'
                        ]]
                    ])
                }
            }
        }

        stage('Scan In_Basket') {
            steps {
                script {
                    echo "üîç Scanning in_basket for new documents..."

                    sh '''
                        echo "========== SCAN IN_BASKET STAGE =========="
                        echo "[DEBUG] Current working directory: $(pwd)"
                        echo "[DEBUG] IN_BASKET variable: ${IN_BASKET}"

                        cd "${IN_BASKET}"
                        echo "[DEBUG] Changed to: $(pwd)"
                        echo "[DEBUG] Directory listing:"
                        ls -la
                        echo ""

                        # Find all documents (not DO_NOT_REMOVE_ME)
                        echo "[DEBUG] Searching for documents (excluding DO_NOT_REMOVE_ME)..."
                        DOC_COUNT=$(find . -maxdepth 1 -type f ! -name "DO_NOT_REMOVE_ME" | wc -l)
                        echo "‚úì Found ${DOC_COUNT} document(s) in in_basket"

                        if [ ${DOC_COUNT} -gt 0 ]; then
                            echo ""
                            echo "Documents ready for processing:"
                            find . -maxdepth 1 -type f ! -name "DO_NOT_REMOVE_ME" | sort | while read doc; do
                                echo "  - $(basename "$doc") ($(stat -c%s "$doc" 2>/dev/null || stat -f%z "$doc" 2>/dev/null) bytes)"
                            done
                        else
                            echo "[WARN] No documents found in in_basket"
                        fi

                        echo "[DEBUG] Writing DOC_COUNT=${DOC_COUNT} to /tmp/doc_count"
                        echo "${DOC_COUNT}" > /tmp/doc_count
                        echo "[DEBUG] Contents of /tmp/doc_count: $(cat /tmp/doc_count)"
                        echo "========== END SCAN IN_BASKET =========="
                        echo ""
                    '''

                    env.DOC_COUNT = readFile('/tmp/doc_count').trim()
                }
            }
        }

        stage('Process Documents') {
            when {
                expression { env.DOC_COUNT != "0" }
            }
            steps {
                script {
                    echo "üì¶ Processing ${DOC_COUNT} document(s)..."

                    sh '''
                        cd "${IN_BASKET}"

                        # Process each document
                        find . -maxdepth 1 -type f ! -name "DO_NOT_REMOVE_ME" | sort | while read doc; do
                            doc_name=$(basename "$doc")
                            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                            echo "Processing: ${doc_name}"

                            # For now, just log that we found the document
                            # Full processing logic to be implemented in next stage
                            echo "  Status: Queued for disposition"
                        done
                    '''
                }
            }
        }

        stage('Classify & Extract Metadata') {
            when {
                expression { env.DOC_COUNT != "0" }
            }
            steps {
                script {
                    echo "üî¨ Using Claude to classify documents and extract metadata..."

                    sh '''#!/bin/bash
                        echo "========== CLASSIFY & EXTRACT METADATA =========="
                        cd "${IN_BASKET}"
                        echo "[DEBUG] Working directory: $(pwd)"

                        # Create temporary metadata directory
                        echo "[DEBUG] Creating metadata directory: /tmp/disposition-metadata"
                        mkdir -p /tmp/disposition-metadata
                        echo "[DEBUG] Directory created. Contents:"
                        ls -la /tmp/disposition-metadata

                        # Read each document and use Claude to classify
                        echo "[DEBUG] Finding documents..."
                        DOC_FILES=$(find . -maxdepth 1 -type f ! -name "DO_NOT_REMOVE_ME" | sort)
                        FILE_COUNT=$(echo "${DOC_FILES}" | wc -l)
                        echo "[DEBUG] Found ${FILE_COUNT} document(s)"
                        echo "${DOC_FILES}"

                        echo "${DOC_FILES}" | while read doc; do
                            doc_name=$(basename "$doc")
                            doc_path="${IN_BASKET}/${doc_name}"

                            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                            echo "Analyzing: ${doc_name}"
                            echo "[DEBUG] Document path: ${doc_path}"
                            echo "[DEBUG] File exists: $(test -f "${doc_path}" && echo 'YES' || echo 'NO')"
                            echo "[DEBUG] File size: $(stat -c%s "${doc_path}" 2>/dev/null || stat -f%z "${doc_path}" 2>/dev/null) bytes"

                            # Determine format from extension
                            if [[ "${doc_name}" =~ [.]adoc$ ]]; then
                                FORMAT="asciidoc"
                            elif [[ "${doc_name}" =~ [.](md|markdown)$ ]]; then
                                FORMAT="markdown"
                            elif [[ "${doc_name}" =~ [.]pdf$ ]]; then
                                FORMAT="pdf"
                            else
                                FORMAT="other"
                            fi
                            echo "[DEBUG] FORMAT: ${FORMAT}"

                            # Classify document based on CONTENT (not filename)
                            echo "  ‚Üí Extracting document type from content..."

                            DOC_TYPE="UNKNOWN"
                            DOC_TITLE="${doc_name%.*}"
                            REQUIRED_SIGNERS=""

                            # Try to extract type from document content
                            if [ "${FORMAT}" = "markdown" ] || [ "${FORMAT}" = "asciidoc" ]; then
                                # PATTERN 1: Look for **Document ID:** field (StarForth template format)
                                # Example: **Document ID:** [TICKET-ID] (e.g., CAPA-2025-001, FEATURE-2025-001)
                                if grep -q '^\*\*Document ID:\*\*' "${doc_path}" 2>/dev/null; then
                                    DOC_ID_LINE=$(grep '^\*\*Document ID:\*\*' "${doc_path}" | head -1)
                                    echo "[DEBUG] Found Document ID field: ${DOC_ID_LINE}"

                                    # Extract ticket ID from the field
                                    # Look for pattern like CAPA-2025-001 in the line
                                    if [[ "${DOC_ID_LINE}" =~ \[([A-Z]+)-([0-9]+-[0-9]+)\] ]]; then
                                        DOC_TYPE="${BASH_REMATCH[1]}"
                                        DOC_ID="${BASH_REMATCH[2]}"
                                        DOC_TITLE="${DOC_TYPE}-${DOC_ID}"
                                        echo "[DEBUG] Extracted type from Document ID: ${DOC_TYPE} (ID: ${DOC_ID})"
                                    fi
                                fi

                                # PATTERN 2: Look for checked checkboxes in Classification section
                                # Example: - [x] **CAPA** (Corrective/Preventive Action)
                                if [ "${DOC_TYPE}" = "UNKNOWN" ]; then
                                    # Find the Classification section and look for checked boxes
                                    CLASSIFICATION=$(grep -A 10 '^## Classification' "${doc_path}" 2>/dev/null | grep '\[x\]' | head -1)
                                    if [ -n "${CLASSIFICATION}" ]; then
                                        echo "[DEBUG] Found checked classification: ${CLASSIFICATION}"
                                        # Extract type from the checked box line
                                        if [[ "${CLASSIFICATION}" =~ \*\*([A-Z]+)\*\* ]]; then
                                            DOC_TYPE="${BASH_REMATCH[1]}"
                                            echo "[DEBUG] Extracted type from Classification checkbox: ${DOC_TYPE}"
                                        fi
                                    fi
                                fi

                                # PATTERN 3: Look for **Submitted by:** field for signer info
                                # Example: **Submitted by:** [Full Name] <[email]>
                                SUBMITTED_BY=$(grep '^\*\*Submitted by:\*\*' "${doc_path}" 2>/dev/null | head -1 | sed 's/.*\*\*Submitted by:\*\*[[:space:]]*\[//;s/\].*//')
                                if [ -n "${SUBMITTED_BY}" ]; then
                                    echo "[DEBUG] Found submitter: ${SUBMITTED_BY}"
                                    REQUIRED_SIGNERS="${SUBMITTED_BY}"
                                fi

                                # PATTERN 4: Look for main title/heading
                                if [ "${FORMAT}" = "markdown" ]; then
                                    # For markdown: # TITLE or **TITLE**
                                    TITLE_LINE=$(grep "^#" "${doc_path}" 2>/dev/null | head -1 | sed 's/^#+[[:space:]]*//')
                                    if [ -n "${TITLE_LINE}" ]; then
                                        DOC_TITLE="${TITLE_LINE}"
                                        echo "[DEBUG] Extracted title from heading: ${DOC_TITLE}"
                                    fi
                                fi

                                # PATTERN 5: Fallback - look for governance keywords in content
                                if [ "${DOC_TYPE}" = "UNKNOWN" ]; then
                                    if grep -qi "failure.*mode.*effects\|FMEA" "${doc_path}" 2>/dev/null; then
                                        DOC_TYPE="FMEA"
                                        echo "[DEBUG] Inferred type from content: FMEA"
                                    elif grep -qi "engineering.*change.*request\|ECR" "${doc_path}" 2>/dev/null; then
                                        DOC_TYPE="ECR"
                                        echo "[DEBUG] Inferred type from content: ECR"
                                    elif grep -qi "engineering.*change.*order\|ECO" "${doc_path}" 2>/dev/null; then
                                        DOC_TYPE="ECO"
                                        echo "[DEBUG] Inferred type from content: ECO"
                                    elif grep -qi "corrective.*preventive\|CAPA" "${doc_path}" 2>/dev/null; then
                                        DOC_TYPE="CAPA"
                                        echo "[DEBUG] Inferred type from content: CAPA"
                                    fi
                                fi
                            fi

                            # FALLBACK: Try filename pattern as absolute last resort
                            if [ "${DOC_TYPE}" = "UNKNOWN" ]; then
                                if [[ "${doc_name}" =~ ^([A-Z]+)-[0-9]+ ]]; then
                                    DOC_TYPE="${BASH_REMATCH[1]}"
                                    echo "[DEBUG] Fallback: Extracted type from filename: ${DOC_TYPE}"
                                else
                                    echo "[WARN] Could not determine document type - continuing with UNKNOWN"
                                    DOC_TYPE="UNKNOWN"
                                fi
                            fi

                            # Default signer if none found in document
                            if [ -z "${REQUIRED_SIGNERS}" ]; then
                                REQUIRED_SIGNERS="rajames440"
                                echo "[DEBUG] Using default signer: rajames440"
                            fi

                            # Create metadata JSON with simple classification
                            echo "[DEBUG] Creating metadata file: /tmp/disposition-metadata/${doc_name}.json"

                            # Build JSON array for signers
                            SIGNERS_JSON="[]"
                            if [ -n "${REQUIRED_SIGNERS}" ]; then
                                # Convert space/comma-separated list to JSON array
                                SIGNERS_JSON=$(echo "${REQUIRED_SIGNERS}" | tr ',' '\n' | tr ' ' '\n' | grep -v '^$' | jq -R . | jq -s . 2>/dev/null || echo "[\"${REQUIRED_SIGNERS}\"]")
                            fi

                            cat > "/tmp/disposition-metadata/${doc_name}.json" << METADATA
{
  "type": "${DOC_TYPE}",
  "title": "${DOC_TITLE}",
  "required_signers": ${SIGNERS_JSON},
  "format": "${FORMAT}",
  "needs_conversion": false
}
METADATA

                            # Display results
                            if [ -f "/tmp/disposition-metadata/${doc_name}.json" ]; then
                                echo "[DEBUG] Metadata file created successfully"
                                echo "[DEBUG] Metadata file contents:"
                                cat "/tmp/disposition-metadata/${doc_name}.json"

                                DOC_TYPE=$(jq -r '.type // "UNKNOWN"' "/tmp/disposition-metadata/${doc_name}.json")
                                DOC_TITLE=$(jq -r '.title // ""' "/tmp/disposition-metadata/${doc_name}.json")
                                SIGNERS=$(jq -r '.required_signers // []' "/tmp/disposition-metadata/${doc_name}.json")

                                echo "  Type: ${DOC_TYPE}"
                                echo "  Title: ${DOC_TITLE}"
                                echo "  Signers Required: ${SIGNERS}"
                            else
                                echo "[ERROR] Failed to create metadata file!"
                            fi
                        done

                        echo ""
                        echo "[DEBUG] All metadata files created:"
                        ls -la /tmp/disposition-metadata/
                        echo "========== END CLASSIFY & EXTRACT METADATA =========="
                        echo ""
                    '''
                }
            }
        }

        stage('Extract Quality & Governance Keywords') {
            when {
                expression { env.DOC_COUNT != "0" }
            }
            steps {
                script {
                    echo "üîç Extracting quality & governance keywords from document content..."

                    sh '''#!/bin/bash
                        echo "========== EXTRACT QUALITY & GOVERNANCE KEYWORDS =========="
                        cd "${WORKSPACE_REPO}"

                        KEYWORDS_FILE="${WORKSPACE_REPO}/keywords.txt"

                        if [ ! -f "${KEYWORDS_FILE}" ]; then
                            echo "[WARN] Keywords file not found at ${KEYWORDS_FILE}"
                            echo "[DEBUG] Skipping keyword extraction stage"
                            echo "========== END EXTRACT KEYWORDS =========="
                            exit 0
                        fi

                        echo "[DEBUG] Keywords file found: ${KEYWORDS_FILE}"

                        # Process each document with keyword extraction
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)
                            doc_path="${IN_BASKET}/${doc_name}"

                            if [ ! -f "${doc_path}" ]; then
                                echo "[WARN] Document not found: ${doc_name}"
                                continue
                            fi

                            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                            echo "Scanning: ${doc_name}"

                            # Read document content (lowercased for case-insensitive matching)
                            DOC_CONTENT=$(cat "${doc_path}" | tr '[:upper:]' '[:lower:]')

                            # Parse keywords file and check each category
                            KEYWORD_FINDINGS="{\"found_keywords\": {}}"
                            CATEGORY_FLAGS="[]"

                            while IFS='|' read -r category keywords_str; do
                                # Skip comments and empty lines
                                [[ "${category}" =~ ^# ]] && continue
                                [ -z "${category}" ] && continue

                                echo "  Checking category: ${category}"

                                # Split keywords by comma
                                FOUND_IN_CATEGORY=()
                                IFS=',' read -ra KEYWORD_ARRAY <<< "${keywords_str}"

                                for keyword in "${KEYWORD_ARRAY[@]}"; do
                                    keyword=$(echo "${keyword}" | xargs) # trim whitespace

                                    # Case-insensitive search
                                    if echo "${DOC_CONTENT}" | grep -qi "${keyword}"; then
                                        FOUND_IN_CATEGORY+=("${keyword}")
                                        echo "    ‚úì Found: ${keyword}"
                                    fi
                                done

                                # Add to findings if keywords found in this category
                                if [ ${#FOUND_IN_CATEGORY[@]} -gt 0 ]; then
                                    echo "  ‚Üí ${category}: ${#FOUND_IN_CATEGORY[@]} keyword(s) found"
                                fi

                            done < "${KEYWORDS_FILE}"

                            echo "  Keywords extraction complete for: ${doc_name}"
                        done

                        echo ""
                        echo "[DEBUG] Keyword extraction stage completed"
                        echo "========== END EXTRACT KEYWORDS =========="
                    '''
                }
            }
        }

        stage('Verify Git Status') {
            steps {
                script {
                    echo "‚úì Verifying git status..."

                    sh '''
                        cd "${WORKSPACE_REPO}"

                        # Check git config
                        echo "Git configuration:"
                        git config user.name || echo "  user.name not set"
                        git config user.email || echo "  user.email not set"

                        # Show current branch
                        echo "Current branch: $(git rev-parse --abbrev-ref HEAD)"

                        # Show status
                        echo "Status:"
                        git status --short | head -20
                    '''
                }
            }
        }

        stage('Convert Formats & Add Signatures') {
            when {
                expression { env.DOC_COUNT != "0" }
            }
            steps {
                script {
                    echo "üîÑ Converting formats to AsciiDoc and adding signature blocks..."

                    sh '''#!/bin/bash
                        cd "${IN_BASKET}"

                        # Process each document metadata
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)
                            doc_path="${IN_BASKET}/${doc_name}"
                            metadata=$(cat "${metadata_file}")

                            echo "Processing metadata for: ${doc_name}"

                            # Check if format conversion needed
                            NEEDS_CONVERSION=$(echo "${metadata}" | jq -r '.needs_conversion // false')
                            FORMAT=$(echo "${metadata}" | jq -r '.format // "unknown"')
                            DOC_TYPE=$(echo "${metadata}" | jq -r '.type // "UNKNOWN"')

                            if [ "${NEEDS_CONVERSION}" = "true" ] && [ "${FORMAT}" != "asciidoc" ]; then
                                echo "  ‚Üí Converting from ${FORMAT} to AsciiDoc..."

                                # Use Claude to convert document format
                                DOC_CONTENT=$(cat "${doc_path}")
                                claude --print "Convert this ${FORMAT} document to AsciiDoc format. Preserve all content, structure, and meaning. Output ONLY the AsciiDoc content, no explanations.

\\${DOC_CONTENT}" \
                                    > "${doc_path}.asciidoc" 2>&1 || {
                                    echo "  ‚ö†Ô∏è Conversion failed for ${doc_name}"
                                    continue
                                }

                                # Replace original with converted version
                                mv "${doc_path}.asciidoc" "${doc_path}"
                                echo "  ‚úì Converted to AsciiDoc"
                            fi

                            # Add signature block if controlled document (use bash, not Claude)
                            if [[ ! "${DOC_TYPE}" =~ ^(ART|MIN|REL|RMP)$ ]]; then
                                echo "  ‚Üí Adding signature block..."

                                # Build signature rows from metadata
                                SIGNERS=$(echo "${metadata}" | jq -r '.required_signers[]')
                                SIGNER_ROWS=""
                                while IFS= read -r signer; do
                                    SIGNER_ROWS="${SIGNER_ROWS}| ${signer} | Pending |  |
"
                                done <<< "${SIGNERS}"

                                # Append signature block to document (simple bash append, no Claude)
                                cat >> "${doc_path}" << SIGBLOCK

== Signatures

|===
| Signer | Status | Date | Signature

${SIGNER_ROWS}|===
SIGBLOCK

                                if [ $? -eq 0 ]; then
                                    echo "  ‚úì Signature block added"
                                else
                                    echo "  ‚ö†Ô∏è Signature block addition failed"
                                fi
                            fi
                        done
                    '''
                }
            }
        }

        stage('Route to Pending') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üìÇ Routing processed documents to Pending/[TYPE]/ directories..."

                    sh '''
                        echo "========== ROUTE TO PENDING STAGE =========="
                        cd "${WORKSPACE_REPO}"
                        echo "[DEBUG] Current working directory: $(pwd)"

                        # Create Pending directory if it doesn't exist
                        mkdir -p Pending
                        echo "[DEBUG] Pending directory exists"

                        # Process each document from metadata
                        echo "[DEBUG] Finding metadata files..."
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)
                            doc_path="${IN_BASKET}/${doc_name}"

                            if [ ! -f "${doc_path}" ]; then
                                echo "‚ö†Ô∏è Document not found: ${doc_name}"
                                continue
                            fi

                            echo "[DEBUG] Document file size: $(stat -c%s "${doc_path}" 2>/dev/null || stat -f%z "${doc_path}" 2>/dev/null) bytes"

                            # Extract document type from metadata
                            DOC_TYPE=$(jq -r '.type // "UNKNOWN"' "${metadata_file}") || exit 1
                            DOC_TITLE=$(jq -r '.title // ""' "${metadata_file}") || exit 1

                            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                            echo "Routing: ${doc_name}"
                            echo "  Type: ${DOC_TYPE}"
                            echo "  Title: ${DOC_TITLE}"

                            # Create type-specific pending directory
                            PENDING_TYPE_DIR="Pending/${DOC_TYPE}"
                            mkdir -p "${PENDING_TYPE_DIR}" || exit 1
                            echo "[DEBUG] Created directory: ${PENDING_TYPE_DIR}"

                            # Move document to Pending directory (atomic operation)
                            echo "[DEBUG] Moving ${doc_name} from ${doc_path} to ${PENDING_TYPE_DIR}/${doc_name}"
                            mv "${doc_path}" "${PENDING_TYPE_DIR}/${doc_name}" || exit 1

                            # Verify the file was moved successfully
                            if [ ! -f "${PENDING_TYPE_DIR}/${doc_name}" ]; then
                                echo "‚ùå CRITICAL: File move failed - document not found at destination"
                                exit 1
                            fi
                            echo "[DEBUG] ‚úì File verified at destination"

                            # Verify file was removed from source
                            if [ -f "${doc_path}" ]; then
                                echo "‚ùå CRITICAL: File still exists in source - move may have been a copy"
                                exit 1
                            fi
                            echo "[DEBUG] ‚úì File removed from source"

                            # Verify destination file size matches source (file integrity check)
                            DEST_SIZE=$(stat -c%s "${PENDING_TYPE_DIR}/${doc_name}" 2>/dev/null || stat -f%z "${PENDING_TYPE_DIR}/${doc_name}" 2>/dev/null)
                            SOURCE_SIZE=$(cat /tmp/doc-${doc_name}.source-size 2>/dev/null || echo "0")
                            echo "[DEBUG] Destination file size: ${DEST_SIZE} bytes"

                            # Save document type and title for later use
                            echo "${DOC_TYPE}" > "/tmp/doc-${doc_name}.type" || exit 1
                            echo "${DOC_TITLE}" > "/tmp/doc-${doc_name}.title" || exit 1
                            echo "${DEST_SIZE}" > "/tmp/doc-${doc_name}.routed-size" || exit 1

                            echo "  ‚úì Successfully routed to Pending/${DOC_TYPE}/"
                        done

                        echo ""
                        echo "[DEBUG] Route to Pending stage completed successfully"
                        echo "========== END ROUTE TO PENDING STAGE =========="
                    '''
                }
            }
        }

        stage('Clean in_basket') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üóëÔ∏è Removing processed documents from in_basket..."

                    sh '''
                        echo "========== CLEAN IN_BASKET STAGE =========="
                        cd "${WORKSPACE_REPO}"
                        echo "[DEBUG] Current working directory: $(pwd)"

                        # Remove successfully routed documents from in_basket
                        echo "[DEBUG] Finding processed documents to remove..."
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)
                            doc_path="${IN_BASKET}/${doc_name}"

                            # Only remove if document no longer exists in in_basket
                            # (successfully moved to Pending)
                            if [ ! -f "${doc_path}" ]; then
                                echo "‚úì ${doc_name} already removed from in_basket"
                            else
                                # Document still in in_basket - remove it
                                echo "Removing: ${doc_name}"
                                rm -f "${doc_path}"

                                # Verify removal
                                if [ ! -f "${doc_path}" ]; then
                                    echo "  ‚úì Successfully removed from in_basket"
                                else
                                    echo "  ‚ö†Ô∏è Failed to remove (permission issue?)"
                                fi
                            fi
                        done

                        echo ""
                        echo "Documents remaining in in_basket:"
                        find "${IN_BASKET}" -maxdepth 1 -type f ! -name "DO_NOT_REMOVE_ME" | wc -l

                        echo "[DEBUG] Clean in_basket stage completed"
                        echo "========== END CLEAN IN_BASKET STAGE =========="
                    '''
                }
            }
        }

        stage('Create Feature Branch') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üåø Creating feature branch for document processing..."

                    sh '''
                        echo "========== CREATE FEATURE BRANCH =========="
                        cd "${WORKSPACE_REPO}"
                        echo "[DEBUG] Working directory: $(pwd)"
                        echo "[DEBUG] Current branch before: $(git rev-parse --abbrev-ref HEAD)"

                        # Create a single branch for this disposition batch
                        BRANCH_NAME="doc/disposition-$(date +%s)"
                        echo "[DEBUG] Creating new branch: ${BRANCH_NAME}"

                        git checkout -b "${BRANCH_NAME}"
                        echo "‚úì Created branch: ${BRANCH_NAME}"
                        echo "[DEBUG] Current branch after: $(git rev-parse --abbrev-ref HEAD)"
                        echo "${BRANCH_NAME}" > /tmp/branch_name
                        echo "[DEBUG] Wrote BRANCH_NAME to /tmp/branch_name: $(cat /tmp/branch_name)"
                        echo "========== END CREATE FEATURE BRANCH =========="
                    '''

                    env.BRANCH_NAME = readFile('/tmp/branch_name').trim()
                    echo "[GROOVY] env.BRANCH_NAME set to: ${env.BRANCH_NAME}"
                }
            }
        }

        stage('Create Routing PR (PR #1)') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üìã Creating internal PR #1: Document routing to Pending/..."

                    sh '''
                        cd "${WORKSPACE_REPO}"

                        # Set git configuration for commits
                        git config user.name "${GIT_AUTHOR_NAME}"
                        git config user.email "${GIT_AUTHOR_EMAIL}"

                        # Stage all Pending directory changes
                        git add Pending/

                        # Check if there are changes to commit
                        if git diff --cached --quiet; then
                            echo "‚ÑπÔ∏è No changes to commit (DRY_RUN or no documents routed)"
                        else
                            # Create commit with timestamp
                            git commit -m "docs(disposition): Route ${DOC_COUNT} document(s) to Pending/

- Processing timestamp: ${TIMESTAMP}
- Documents ready for signature collection
- PR #1 of 4: Initial routing to workflow

[Disposition Pipeline]"

                            echo "‚úì PR #1 commit created: $(git rev-parse --short HEAD)"
                            git log --oneline -1
                        fi
                    '''
                }
            }
        }

        stage('Notify Signers') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üìß Notifying required signers via GitHub..."

                    sh '''
                        cd "${WORKSPACE_REPO}"

                        # Process each document to identify signers
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)

                            # Extract signers from metadata
                            SIGNERS=$(jq -r '.required_signers[]?' "${metadata_file}")
                            DOC_TITLE=$(jq -r '.title // ""' "${metadata_file}")
                            DOC_TYPE=$(jq -r '.type // "UNKNOWN"' "${metadata_file}")

                            if [ -z "${SIGNERS}" ]; then
                                echo "‚ÑπÔ∏è No signers required for: ${doc_name}"
                                continue
                            fi

                            echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
                            echo "üì¢ Notifying signers for: ${doc_name}"
                            echo "   Title: ${DOC_TITLE}"
                            echo "   Type: ${DOC_TYPE}"
                            echo "   Signers:"

                            # Build list of signers with @ mentions
                            SIGNER_MENTIONS=""
                            echo "${SIGNERS}" | while read signer; do
                                echo "     - ${signer}"
                                SIGNER_MENTIONS="${SIGNER_MENTIONS}@${signer} "
                            done

                            # Create GitHub issue notification
                            if command -v gh &> /dev/null; then
                                echo "  ‚Üí Creating GitHub issue notification..."

                                # Build signer list for the issue
                                SIGNERS_LIST=$(echo "${SIGNERS}" | sed 's/^/- @/')

                                # Write issue body to temp file (pure bash, no Groovy parsing)
                                cat > /tmp/issue_body.txt << 'ISSUE_EOF'
Document pending signature collection.

**Document:** [DOCUMENT_NAME_PLACEHOLDER]
**Type:** DOCUMENT_TYPE_PLACEHOLDER
**Title:** DOCUMENT_TITLE_PLACEHOLDER

**Required Signers:**
SIGNERS_PLACEHOLDER

**Action Required:**
1. Review document in Pending/DOCUMENT_TYPE_PLACEHOLDER/DOCUMENT_NAME_PLACEHOLDER
2. Sign with GPG: gpg --detach-sign --armor DOCUMENT_NAME_PLACEHOLDER
3. Create detached signature: DOCUMENT_NAME_PLACEHOLDER.[your-username].asc
4. Commit to repository or notify pipeline

**Timeline:**
- Day 1: Reminder notification
- Day 3: PM escalation if not signed

Created: TIMESTAMP_PLACEHOLDER
Branch: BRANCH_PLACEHOLDER
ISSUE_EOF

                                # Replace placeholders with actual values using bash
                                sed -i "s|DOCUMENT_NAME_PLACEHOLDER|${doc_name}|g" /tmp/issue_body.txt
                                sed -i "s|DOCUMENT_TYPE_PLACEHOLDER|${DOC_TYPE}|g" /tmp/issue_body.txt
                                sed -i "s|DOCUMENT_TITLE_PLACEHOLDER|${DOC_TITLE}|g" /tmp/issue_body.txt
                                sed -i "s|SIGNERS_PLACEHOLDER|${SIGNERS_LIST}|g" /tmp/issue_body.txt
                                sed -i "s|TIMESTAMP_PLACEHOLDER|${TIMESTAMP}|g" /tmp/issue_body.txt
                                sed -i "s|BRANCH_PLACEHOLDER|${BRANCH_NAME}|g" /tmp/issue_body.txt

                                # Read the file into a variable
                                ISSUE_BODY=$(cat /tmp/issue_body.txt)

                                gh issue create \
                                  --title "üìã Document Pending Signature: ${doc_name}" \
                                  --body "${ISSUE_BODY}" \
                                  --label "governance,signature-needed" \
                                  --assignee ${SIGNERS} 2>&1 || {
                                    echo "  ‚ö†Ô∏è GitHub issue creation may have failed (check below)"
                                }

                                echo "  ‚úì GitHub issue created and signers assigned"
                            else
                                echo "  ‚ö†Ô∏è gh CLI not available, falling back to notification log"
                                echo "[NOTIFY] GitHub Issue: ${doc_name}" >> /tmp/notification-log
                                echo "${SIGNERS}" | while read signer; do
                                    echo "[NOTIFY] @${signer}: Please sign ${doc_name}" >> /tmp/notification-log
                                done
                            fi
                        done

                        # Summary
                        if [ -f /tmp/notification-log ]; then
                            echo ""
                            echo "Notification Summary:"
                            cat /tmp/notification-log
                        fi
                    '''
                }
            }
        }

        stage('Setup Escalation Tracking') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "‚è∞ Setting up escalation tracking for pending documents..."

                    sh '''
                        # Create escalation tracking directory
                        mkdir -p "${WORKSPACE_REPO}/Security/Escalations"

                        # Process each document
                        find /tmp/disposition-metadata -name "*.json" | sort | while read metadata_file; do
                            doc_name=$(basename "${metadata_file}" .json)
                            DOC_TITLE=$(jq -r '.title // ""' "${metadata_file}")
                            DOC_TYPE=$(jq -r '.type // ""' "${metadata_file}")
                            SIGNERS=$(jq -r '.required_signers[]?' "${metadata_file}")

                            echo "Setting up escalation for: ${doc_name}"

                            # Create escalation tracking file
                            ESCALATION_FILE="${WORKSPACE_REPO}/Security/Escalations/${doc_name}.escalation"
                            cat > "${ESCALATION_FILE}" << ESCALATION
# Escalation Tracking: ${doc_name}
title: ${DOC_TITLE}
type: ${DOC_TYPE}
routed_at: ${TIMESTAMP}
day1_reminder: $(date -u -d '+1 day' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v+1d +%Y-%m-%dT%H:%M:%SZ)
day3_escalate_pm: $(date -u -d '+3 days' +%Y-%m-%dT%H:%M:%SZ 2>/dev/null || date -u -v+3d +%Y-%m-%dT%H:%M:%SZ)
signers_required:
${SIGNERS:+$(echo "${SIGNERS}" | sed 's/^/  - /')}
status: PENDING_SIGNATURES
ESCALATION

                            if [ -f "${ESCALATION_FILE}" ]; then
                                echo "  ‚úì Escalation tracking created"
                            fi
                        done

                        # List all tracked escalations
                        echo ""
                        echo "Active Escalations:"
                        ls -la "${WORKSPACE_REPO}/Security/Escalations/" 2>/dev/null | tail -n +4 || echo "  (none)"
                    '''
                }
            }
        }

        stage('Update Security Log') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üîê Updating Security Event Log..."

                    sh '''
                        SEC_LOG="${WORKSPACE_REPO}/Security/SEC_LOG.adoc"

                        if [ ! -f "${SEC_LOG}" ]; then
                            echo "‚ö†Ô∏è Security log not found at ${SEC_LOG}"
                            exit 0
                        fi

                        # Append disposition events to security log
                        cat >> "${SEC_LOG}" << LOG_ENTRY

== Disposition Event: ${TIMESTAMP}

[cols="1,3"]
|===
|Event|${DOC_COUNT} document(s) routed to Pending
|Branch|${BRANCH_NAME}
|Status|PENDING_SIGNATURES
|Action|Awaiting required signatures or PM override
|===

LOG_ENTRY

                        echo "‚úì Security log updated"
                    '''
                }
            }
        }

        stage('Commit Workflow Changes') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üíæ Committing workflow state changes..."

                    sh '''
                        cd "${WORKSPACE_REPO}"

                        git config user.name "${GIT_AUTHOR_NAME}"
                        git config user.email "${GIT_AUTHOR_EMAIL}"

                        # Stage escalation and log changes
                        git add Security/Escalations/ || true
                        git add Security/SEC_LOG.adoc || true

                        if ! git diff --cached --quiet; then
                            git commit -m "docs(disposition): Update escalation tracking and security log

- Setup Day 1 reminder and Day 3 PM escalation tracking
- Record disposition event in Security Event Log
- Timestamp: ${TIMESTAMP}
- Branch: ${BRANCH_NAME}

[Disposition Pipeline - Escalation Setup]"

                            echo "‚úì Workflow changes committed"
                        else
                            echo "‚ÑπÔ∏è No workflow changes to commit"
                        fi
                    '''
                }
            }
        }

        stage('Push to GitHub') {
            when {
                expression { env.DOC_COUNT != "0" && !params.DRY_RUN }
            }
            steps {
                script {
                    echo "üöÄ Pushing disposition changes to GitHub..."

                    withCredentials([usernamePassword(credentialsId: 'github-credentials', usernameVariable: 'GIT_USER', passwordVariable: 'GIT_TOKEN')]) {
                        sh '''
                            cd "${WORKSPACE_REPO}"

                            echo "[DEBUG] Configuring git credentials for push..."
                            # Configure git to use the token for authentication
                            git config credential.helper store
                            echo "https://${GIT_USER}:${GIT_TOKEN}@github.com" > ~/.git-credentials
                            chmod 600 ~/.git-credentials
                            echo "[DEBUG] Git credentials configured"

                            # Check if there are commits to push
                            COMMITS=$(git rev-list origin/master..HEAD 2>/dev/null | wc -l)
                            echo "[DEBUG] Commits to push: ${COMMITS}"

                            if [ "${COMMITS}" -eq 0 ]; then
                                echo "‚ÑπÔ∏è No commits to push"
                                exit 0
                            fi

                            echo "Current branch: $(git rev-parse --abbrev-ref HEAD)"
                            echo "[DEBUG] Pushing branch: ${BRANCH_NAME}"

                            # Push feature branch to GitHub
                            git push -u origin "${BRANCH_NAME}" 2>&1

                            if [ $? -eq 0 ]; then
                                echo "‚úì Branch pushed: ${BRANCH_NAME}"
                            else
                                echo "‚ö†Ô∏è Failed to push branch"
                                exit 1
                            fi

                            # Show commits to be merged to master
                            echo ""
                            echo "Commits ready for master:"
                            git log --oneline origin/master..HEAD | head -10

                            # Clean up credentials
                            echo "[DEBUG] Cleaning up git credentials..."
                            rm -f ~/.git-credentials
                        '''
                    }
                }
            }
        }

        stage('Summary') {
            steps {
                script {
                    echo ""
                    echo "üìä Disposition Pipeline Summary"
                    echo "===================================="
                    echo "Execution:     ${TIMESTAMP}"
                    echo "Documents:     ${DOC_COUNT}"
                    if (env.BRANCH_NAME) {
                        echo "Branch:        ${BRANCH_NAME}"
                    }
                    echo ""
                    echo "Pipeline Stages:"
                    echo "  ‚úì Scanned in_basket"
                    echo "  ‚úì Classified documents"
                    echo "  ‚úì Converted formats & added signatures"
                    echo "  ‚úì Routed to Pending/[TYPE]/"
                    echo "  ‚úì Created PR #1 (routing)"
                    echo "  ‚úì Notified signers"
                    echo "  ‚úì Setup escalation tracking"
                    echo "  ‚úì Updated security log"
                    echo ""
                    if (params.DRY_RUN) {
                        echo "Mode:          DRY RUN (no commits/pushes)"
                    } else {
                        echo "Mode:          LIVE (changes committed & pushed)"
                    }
                    echo ""
                    echo "Next Steps:"
                    echo "  ‚Üí Signers verify and sign documents in Pending/[TYPE]/"
                    echo "  ‚Üí Day 1: Reminder notification sent"
                    echo "  ‚Üí Day 3: PM escalation for unsigned documents"
                    echo "  ‚Üí Upon completion: Create PR #4 (move to vault)"
                    echo "===================================="
                }
            }
        }
    }

    post {
        always {
            script {
                echo "‚úÖ Pipeline execution complete"
                echo "Build Status: ${currentBuild.result}"
            }
        }

        success {
            script {
                echo "‚úì Documents processed successfully"

                // Send success email
                if (env.DOC_COUNT != "0" && !params.DRY_RUN) {
                    echo "üìß Sending success notification email..."
                    mail(
                        subject: "‚úì StarForth Disposition Pipeline Success - ${env.DOC_COUNT} document(s) routed",
                        body: """
                            Document Disposition Pipeline Execution Summary
                            ==============================================

                            Status: SUCCESS ‚úì
                            Timestamp: ${env.TIMESTAMP}
                            Documents Processed: ${env.DOC_COUNT}
                            Branch: ${env.BRANCH_NAME ?: 'N/A'}

                            Actions Completed:
                            ‚Ä¢ Scanned in_basket for new documents
                            ‚Ä¢ Classified documents and extracted metadata
                            ‚Ä¢ Routed documents to Pending/[TYPE]/ directories
                            ‚Ä¢ Created PR #1 (routing to Pending)
                            ‚Ä¢ Notified signers via GitHub issues
                            ‚Ä¢ Setup escalation tracking (Day 1 & Day 3)
                            ‚Ä¢ Updated Security Event Log
                            ‚Ä¢ Committed workflow changes
                            ‚Ä¢ Pushed changes to GitHub

                            Next Steps:
                            ‚Üí Pull latest changes: git pull origin master
                            ‚Üí Review routed documents in Pending/ directories
                            ‚Üí Check GitHub for signer notifications
                            ‚Üí Signers should verify and sign documents in Pending/[TYPE]/

                            GitHub Repository: https://github.com/rajames440/StarForth-Governance
                            Jenkins Build: ${env.BUILD_URL}
                        """,
                        to: "${env.CHANGE_AUTHOR_EMAIL ?: 'rajames440@gmail.com'}",
                        mimeType: 'text/plain'
                    )
                }
            }
        }

        failure {
            script {
                echo "‚ùå Pipeline encountered errors"

                // Send failure email with debug info
                echo "üìß Sending failure notification email..."
                mail(
                    subject: "‚ùå StarForth Disposition Pipeline FAILED",
                    body: """
                        Document Disposition Pipeline Execution Summary
                        ==============================================

                        Status: FAILED ‚ùå
                        Timestamp: ${env.TIMESTAMP}
                        Documents Processed: ${env.DOC_COUNT ?: 'Unknown'}

                        Pipeline failed during execution. Check the Jenkins logs for details.

                        Debug Information:
                        ‚Ä¢ Build Status: ${currentBuild.result}
                        ‚Ä¢ Build URL: ${env.BUILD_URL}
                        ‚Ä¢ Current Branch: ${env.BRANCH_NAME ?: 'N/A'}
                        ‚Ä¢ Workspace: ${env.WORKSPACE}

                        Common Issues:
                        1. Check GitHub PAT (Personal Access Token) is valid
                        2. Verify Jenkins credential 'github-credentials' is configured
                        3. Check that in_basket/ contains documents
                        4. Review full Jenkins logs for detailed error messages

                        Jenkins Build: ${env.BUILD_URL}
                        GitHub Repository: https://github.com/rajames440/StarForth-Governance
                    """,
                    to: "${env.CHANGE_AUTHOR_EMAIL ?: 'rajames440@gmail.com'}",
                    mimeType: 'text/plain'
                )
            }
        }
    }
}
